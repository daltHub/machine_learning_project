{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gathers weather data \n",
        "## Based on https://github.com/IrishMarineInstitute/OGI_MIPilot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "alQ9MnDZt5oz"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import datetime\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-ueKTvQuAAr",
        "outputId": "6686bd9c-4a18-4651-960c-5e413a588bb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wave_spectral\n",
            "Downloaded 2008\n",
            "Downloaded 2009\n",
            "Downloaded 2010\n",
            "Downloaded 2011\n",
            "Downloaded 2012\n",
            "Downloaded 2013\n",
            "Downloaded 2014\n",
            "Downloaded 2015\n",
            "Downloaded 2016\n",
            "Downloaded 2017\n",
            "Downloaded 2018\n",
            "Downloaded 2019\n",
            "Downloaded 2020\n",
            "Downloaded 2021\n",
            "Full resolution data downloaded. Available as 'data_full_wave_spectral'.\n",
            "Daily availability generated. Available as 'data_avail'.\n"
          ]
        }
      ],
      "source": [
        "typed = 'wave_spectral'\n",
        "print(typed)\n",
        "\n",
        "# Set ERDDAP server details\n",
        "s = 'https://erddap.marine.ie/erddap'\n",
        "p = 'tabledap'\n",
        "r = 'csv'\n",
        "\n",
        "# Set global variables for the parameters without 'buoy_id', 'latitude' and 'longitude' in the list\n",
        "now = datetime.date.today()\n",
        "now_string = now.strftime('%Y-%m-%d')\n",
        "\n",
        "metadata = ['station_id',\n",
        "            'time']\n",
        "\n",
        "# Set variables based on data type (typed)\n",
        "\n",
        "dataset_id = 'IWaveBNetwork_spectral'\n",
        "syear = 2008    \n",
        "master_params = ['PeakPeriod',\n",
        "                  'PeakDirection',\n",
        "                  'PeakSpread',\n",
        "                  'SignificantWaveHeight',\n",
        "                  'EnergyPeriod',\n",
        "                  'MeanWavePeriod_Tm01',\n",
        "                  'MeanWavePeriod_Tm02',\n",
        "                    'qcflag']\n",
        "\n",
        "\n",
        "\n",
        "# Generate parameter component of URL\n",
        "plist = ''\n",
        "for item in metadata + master_params:\n",
        "    plist = plist+item+'%2C'\n",
        "plist = plist[0:-3]\n",
        "\n",
        "# Create dataframe for population\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Iterate by year to reduce risk of time out on large time-series\n",
        "years = range(syear,now.year)\n",
        "for year in years:    \n",
        "    url = s+\"/\"+p+\"/\"+dataset_id+\".\"+r+\"?\"+plist+\"&time%3E=\"+str(year)+\"-01-01T00:00:00Z&time%3C\"+str(year+1)+\"-01-01T00:00:00Z\"\n",
        "    dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
        "    df = pd.concat([df,dfbyyear])\n",
        "    print(\"Downloaded %s\" % (year))\n",
        "\n",
        "# Final call for data from start of current year upto midnight of the current day\n",
        "url = s+\"/\"+p+\"/\"+dataset_id+\".\"+r+\"?\"+plist+\"&time%3E=\"+str(now.year)+\"-01-01T00:00:00Z&time%3C\"+now_string+\"T00:00:00Z\"\n",
        "dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
        "df = pd.concat([df,dfbyyear])\n",
        "print(\"Downloaded %s\" % (str(now.year)))\n",
        "\n",
        "# Make a copy of the unaltered data download\n",
        "data_full_wave_spectral = df.copy()\n",
        "print(\"Full resolution data downloaded. Available as 'data_full_wave_spectral'.\")\n",
        "df.to_csv('full_data/wave_spectral.csv', encoding='utf-8')\n",
        "\n",
        "# Utilise quality control flags to clean data set\n",
        "# Code to be added...\n",
        "\n",
        "\n",
        "\n",
        "# Take a working copy of the downloaded data\n",
        "data = df.copy()\n",
        "\n",
        "# Add columns for date variable\n",
        "data['Date'] = data.index.date\n",
        "\n",
        "# Get a count of data points grouped by station and date\n",
        "data_summ = data.groupby(['station_id','Date']).count().reset_index(level=['station_id','Date'])\n",
        "\n",
        "# Create master availability dataframe to hold count converted to percentage of expected data points per day\n",
        "data_avail = pd.DataFrame()  \n",
        "\n",
        "# Loop through each station due to different data resolutions and calculate percentages\n",
        "for stn in data_summ.station_id.unique().tolist():\n",
        "    data_stn = data_summ[data_summ['station_id']==stn].copy()\n",
        "\n",
        "    # Set the expected number of data points per day for a buoy type or station\n",
        "    if typed == 'weather' or stn == 'Westwave MK4':\n",
        "        res=24\n",
        "    else:\n",
        "        res=48\n",
        "\n",
        "    # Convert counts to percentage\n",
        "    data_stn.loc[:,master_params] = data_stn.loc[:,master_params]/res*100\n",
        "    \n",
        "\n",
        "    # Expand date range to cover full months.\n",
        "    # Enables accurate calculation of monthly perentage return from the daily data when plotting\n",
        "    data_fulldates = pd.DataFrame(index = pd.date_range(data_stn.Date.min() - datetime.timedelta(days=data_stn.Date.min().day-1), \n",
        "                                                      data_stn.Date.max()))\n",
        "\n",
        "    # Add date factors to faciliate plotting\n",
        "    data_fulldates['Date'] = data_fulldates.index.date\n",
        "    data_fulldates['Year'] = data_fulldates.index.year\n",
        "    data_fulldates['Month'] = data_fulldates.index.month\n",
        "    data_fulldates['DOY'] = data_fulldates.index.dayofyear\n",
        "    \n",
        "    # Merge individual station dataframe into master availability dataframe and fill blanks dates with zero\n",
        "    data_fulldates = data_fulldates.merge(data_stn, how='outer', left_on='Date', right_on='Date').fillna(0)\n",
        "    # Set station\n",
        "    data_fulldates.loc[:,'station_id'] = stn\n",
        "    # Add data for the station to the master availability data frame\n",
        "    data_avail = pd.concat([data_avail,data_fulldates])\n",
        "\n",
        "# Set indices and tidy up dataframe\n",
        "data_avail = data_avail.set_index(['station_id', 'Date','Year','Month','DOY'])\n",
        "\n",
        "if typed != 'weather':\n",
        "    qc = 'qcflag'\n",
        "else:\n",
        "    qc = 'QC_Flag'\n",
        "\n",
        "data_avail = data_avail.drop(['qcflag'], axis=1)\n",
        "data_avail.columns = pd.MultiIndex.from_product([data_avail.columns, ['avail']])\n",
        "\n",
        "print(\"Daily availability generated. Available as 'data_avail'.\")\n",
        "data_avail.to_csv('full_data/wave_spectral_availability.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm0jd2y_z4gN",
        "outputId": "2071029c-74be-42a4-aba4-2677f14e9847"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wave_zero\n",
            "Downloaded 2008\n",
            "Downloaded 2009\n",
            "Downloaded 2010\n",
            "Downloaded 2011\n",
            "Downloaded 2012\n",
            "Downloaded 2013\n",
            "Downloaded 2014\n",
            "Downloaded 2015\n",
            "Downloaded 2016\n",
            "Downloaded 2017\n",
            "Downloaded 2018\n",
            "Downloaded 2019\n",
            "Downloaded 2020\n",
            "Downloaded 2021\n",
            "Full resolution data downloaded. Available as 'data_full_wave_zero'.\n",
            "Daily availability generated. Available as 'data_avail'.\n"
          ]
        }
      ],
      "source": [
        "typed = 'wave_zero'\n",
        "print(typed)\n",
        "\n",
        "# Set ERDDAP server details\n",
        "s = 'https://erddap.marine.ie/erddap'\n",
        "p = 'tabledap'\n",
        "r = 'csv'\n",
        "\n",
        "# Set global variables for the parameters without 'buoy_id', 'latitude' and 'longitude' in the list\n",
        "now = datetime.date.today()\n",
        "now_string = now.strftime('%Y-%m-%d')\n",
        "\n",
        "metadata = ['station_id',\n",
        "            'time']\n",
        "\n",
        "# Set variables based on data type (typed)\n",
        "\n",
        "\n",
        "dataset_id = 'IWaveBNetwork_zerocrossing'\n",
        "syear = 2008    \n",
        "master_params = ['Hmax',\n",
        "                  'HmaxPeriod',\n",
        "                  'Havg',\n",
        "                  'Tavg',\n",
        "                  'qcflag']\n",
        "\n",
        "\n",
        "\n",
        "# Generate parameter component of URL\n",
        "plist = ''\n",
        "for item in metadata + master_params:\n",
        "    plist = plist+item+'%2C'\n",
        "plist = plist[0:-3]\n",
        "\n",
        "# Create dataframe for population\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Iterate by year to reduce risk of time out on large time-series\n",
        "years = range(syear,now.year)\n",
        "for year in years:    \n",
        "    url = s+\"/\"+p+\"/\"+dataset_id+\".\"+r+\"?\"+plist+\"&time%3E=\"+str(year)+\"-01-01T00:00:00Z&time%3C\"+str(year+1)+\"-01-01T00:00:00Z\"\n",
        "    dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
        "    df = pd.concat([df,dfbyyear])\n",
        "    print(\"Downloaded %s\" % (year))\n",
        "\n",
        "# Final call for data from start of current year upto midnight of the current day\n",
        "url = s+\"/\"+p+\"/\"+dataset_id+\".\"+r+\"?\"+plist+\"&time%3E=\"+str(now.year)+\"-01-01T00:00:00Z&time%3C\"+now_string+\"T00:00:00Z\"\n",
        "dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
        "df = pd.concat([df,dfbyyear])\n",
        "print(\"Downloaded %s\" % (str(now.year)))\n",
        "\n",
        "# Make a copy of the unaltered data download\n",
        "data_full_wave_zero = df.copy()\n",
        "print(\"Full resolution data downloaded. Available as 'data_full_wave_zero'.\")\n",
        "df.to_csv('full_data/wave_zero.csv', encoding='utf-8')\n",
        "\n",
        "\n",
        "# Utilise quality control flags to clean data set\n",
        "# Code to be added...\n",
        "\n",
        "\n",
        "\n",
        "# Take a working copy of the downloaded data\n",
        "data = df.copy()\n",
        "\n",
        "# Add columns for date variable\n",
        "data['Date'] = data.index.date\n",
        "\n",
        "# Get a count of data points grouped by station and date\n",
        "data_summ = data.groupby(['station_id','Date']).count().reset_index(level=['station_id','Date'])\n",
        "\n",
        "# Create master availability dataframe to hold count converted to percentage of expected data points per day\n",
        "data_avail = pd.DataFrame()  \n",
        "\n",
        "# Loop through each station due to different data resolutions and calculate percentages\n",
        "for stn in data_summ.station_id.unique().tolist():\n",
        "    data_stn = data_summ[data_summ['station_id']==stn].copy()\n",
        "\n",
        "    # Set the expected number of data points per day for a buoy type or station\n",
        "    if typed == 'weather' or stn == 'Westwave MK4':\n",
        "        res=24\n",
        "    else:\n",
        "        res=48\n",
        "\n",
        "    # Convert counts to percentage\n",
        "    data_stn.loc[:,master_params] = data_stn.loc[:,master_params]/res*100\n",
        "    \n",
        "\n",
        "    # Expand date range to cover full months.\n",
        "    # Enables accurate calculation of monthly perentage return from the daily data when plotting\n",
        "    data_fulldates = pd.DataFrame(index = pd.date_range(data_stn.Date.min() - datetime.timedelta(days=data_stn.Date.min().day-1), \n",
        "                                                      data_stn.Date.max()))\n",
        "\n",
        "    # Add date factors to faciliate plotting\n",
        "    data_fulldates['Date'] = data_fulldates.index.date\n",
        "    data_fulldates['Year'] = data_fulldates.index.year\n",
        "    data_fulldates['Month'] = data_fulldates.index.month\n",
        "    data_fulldates['DOY'] = data_fulldates.index.dayofyear\n",
        "    \n",
        "    # Merge individual station dataframe into master availability dataframe and fill blanks dates with zero\n",
        "    data_fulldates = data_fulldates.merge(data_stn, how='outer', left_on='Date', right_on='Date').fillna(0)\n",
        "    # Set station\n",
        "    data_fulldates.loc[:,'station_id'] = stn\n",
        "    # Add data for the station to the master availability data frame\n",
        "    data_avail = pd.concat([data_avail,data_fulldates])\n",
        "\n",
        "# Set indices and tidy up dataframe\n",
        "data_avail = data_avail.set_index(['station_id', 'Date','Year','Month','DOY'])\n",
        "\n",
        "\n",
        "qc = 'qcflag'\n",
        "\n",
        "\n",
        "data_avail = data_avail.drop(['qcflag'], axis=1)\n",
        "data_avail.columns = pd.MultiIndex.from_product([data_avail.columns, ['avail']])\n",
        "\n",
        "print(\"Daily availability generated. Available as 'data_avail'.\")\n",
        "data_avail.to_csv('full_data/wave_zero_availability.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dtksnkA1EFd",
        "outputId": "747ec5ef-1df7-4604-e65f-216ee435970b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "weather\n",
            "Downloaded 2001\n",
            "Downloaded 2002\n",
            "Downloaded 2003\n",
            "Downloaded 2004\n",
            "Downloaded 2005\n",
            "Downloaded 2006\n",
            "Downloaded 2007\n",
            "Downloaded 2008\n",
            "Downloaded 2009\n",
            "Downloaded 2010\n",
            "Downloaded 2011\n",
            "Downloaded 2012\n",
            "Downloaded 2013\n",
            "Downloaded 2014\n",
            "Downloaded 2015\n",
            "Downloaded 2016\n",
            "Downloaded 2017\n",
            "Downloaded 2018\n",
            "Downloaded 2019\n",
            "Downloaded 2020\n",
            "Downloaded 2021\n",
            "Full resolution data downloaded. Available as 'data_full_weather'.\n",
            "Daily availability generated. Available as 'data_avail'.\n"
          ]
        }
      ],
      "source": [
        "typed = 'weather'\n",
        "print(typed)\n",
        "\n",
        "# Set ERDDAP server details\n",
        "s = 'https://erddap.marine.ie/erddap'\n",
        "p = 'tabledap'\n",
        "r = 'csv'\n",
        "\n",
        "# Set global variables for the parameters without 'buoy_id', 'latitude' and 'longitude' in the list\n",
        "now = datetime.date.today()\n",
        "now_string = now.strftime('%Y-%m-%d')\n",
        "\n",
        "metadata = ['station_id',\n",
        "            'time']\n",
        "\n",
        "# Set variables based on data type (typed)\n",
        "\n",
        "\n",
        "dataset_id = 'IWBNetwork'\n",
        "syear = 2001\n",
        "master_params = ['AtmosphericPressure',\n",
        "                    'WindDirection',\n",
        "                    'WindSpeed',\n",
        "                    'Gust',\n",
        "                    'WaveHeight',\n",
        "                    'WavePeriod',\n",
        "                    'MeanWaveDirection',\n",
        "                    'Hmax',\n",
        "                    'AirTemperature',\n",
        "                    'DewPoint',\n",
        "                    'SeaTemperature',\n",
        "                    'RelativeHumidity',\n",
        "                    'QC_Flag']\n",
        "\n",
        "# Generate parameter component of URL\n",
        "plist = ''\n",
        "for item in metadata + master_params:\n",
        "    plist = plist+item+'%2C'\n",
        "plist = plist[0:-3]\n",
        "\n",
        "# Create dataframe for population\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Iterate by year to reduce risk of time out on large time-series\n",
        "years = range(syear,now.year)\n",
        "for year in years:    \n",
        "    url = s+\"/\"+p+\"/\"+dataset_id+\".\"+r+\"?\"+plist+\"&time%3E=\"+str(year)+\"-01-01T00:00:00Z&time%3C\"+str(year+1)+\"-01-01T00:00:00Z\"\n",
        "    dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
        "    df = pd.concat([df,dfbyyear])\n",
        "    print(\"Downloaded %s\" % (year))\n",
        "\n",
        "# Final call for data from start of current year upto midnight of the current day\n",
        "url = s+\"/\"+p+\"/\"+dataset_id+\".\"+r+\"?\"+plist+\"&time%3E=\"+str(now.year)+\"-01-01T00:00:00Z&time%3C\"+now_string+\"T00:00:00Z\"\n",
        "dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
        "df = pd.concat([df,dfbyyear])\n",
        "print(\"Downloaded %s\" % (str(now.year)))\n",
        "\n",
        "# Make a copy of the unaltered data download\n",
        "data_full_wave_zero = df.copy()\n",
        "print(\"Full resolution data downloaded. Available as 'data_full_weather'.\")\n",
        "df.to_csv('full_data/weather.csv', encoding='utf-8')\n",
        "\n",
        "# Utilise quality control flags to clean data set\n",
        "# Code to be added...\n",
        "\n",
        "\n",
        "\n",
        "# Take a working copy of the downloaded data\n",
        "data = df.copy()\n",
        "\n",
        "# Add columns for date variable\n",
        "data['Date'] = data.index.date\n",
        "\n",
        "# Get a count of data points grouped by station and date\n",
        "data_summ = data.groupby(['station_id','Date']).count().reset_index(level=['station_id','Date'])\n",
        "\n",
        "# Create master availability dataframe to hold count converted to percentage of expected data points per day\n",
        "data_avail = pd.DataFrame()  \n",
        "\n",
        "# Loop through each station due to different data resolutions and calculate percentages\n",
        "for stn in data_summ.station_id.unique().tolist():\n",
        "    data_stn = data_summ[data_summ['station_id']==stn].copy()\n",
        "\n",
        "    # Set the expected number of data points per day for a buoy type or station\n",
        "    if typed == 'weather' or stn == 'Westwave MK4':\n",
        "        res=24\n",
        "    else:\n",
        "        res=48\n",
        "\n",
        "    # Convert counts to percentage\n",
        "    data_stn.loc[:,master_params] = data_stn.loc[:,master_params]/res*100\n",
        "    \n",
        "\n",
        "    # Expand date range to cover full months.\n",
        "    # Enables accurate calculation of monthly perentage return from the daily data when plotting\n",
        "    data_fulldates = pd.DataFrame(index = pd.date_range(data_stn.Date.min() - datetime.timedelta(days=data_stn.Date.min().day-1), \n",
        "                                                      data_stn.Date.max()))\n",
        "\n",
        "    # Add date factors to faciliate plotting\n",
        "    data_fulldates['Date'] = data_fulldates.index.date\n",
        "    data_fulldates['Year'] = data_fulldates.index.year\n",
        "    data_fulldates['Month'] = data_fulldates.index.month\n",
        "    data_fulldates['DOY'] = data_fulldates.index.dayofyear\n",
        "    \n",
        "    # Merge individual station dataframe into master availability dataframe and fill blanks dates with zero\n",
        "    data_fulldates = data_fulldates.merge(data_stn, how='outer', left_on='Date', right_on='Date').fillna(0)\n",
        "    # Set station\n",
        "    data_fulldates.loc[:,'station_id'] = stn\n",
        "    # Add data for the station to the master availability data frame\n",
        "    data_avail = pd.concat([data_avail,data_fulldates])\n",
        "\n",
        "# Set indices and tidy up dataframe\n",
        "data_avail = data_avail.set_index(['station_id', 'Date','Year','Month','DOY'])\n",
        "\n",
        "\n",
        "\n",
        "data_avail = data_avail.drop(['QC_Flag'], axis=1)\n",
        "data_avail.columns = pd.MultiIndex.from_product([data_avail.columns, ['avail']])\n",
        "\n",
        "print(\"Daily availability generated. Available as 'data_avail'.\")\n",
        "data_avail.to_csv('full_data/weather_availability.csv', encoding='utf-8')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "scraper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
