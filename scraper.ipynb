{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scraper.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "alQ9MnDZt5oz"
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import datetime\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-ueKTvQuAAr",
        "outputId": "6686bd9c-4a18-4651-960c-5e413a588bb4"
      },
      "source": [
        "typed = 'wave_spectral'\n",
        "print(typed)\n",
        "\n",
        "# Set ERDDAP server details\n",
        "s = 'https://erddap.marine.ie/erddap'\n",
        "p = 'tabledap'\n",
        "r = 'csv'\n",
        "\n",
        "# Set global variables for the parameters without 'buoy_id', 'latitude' and 'longitude' in the list\n",
        "now = datetime.date.today()\n",
        "now_string = now.strftime('%Y-%m-%d')\n",
        "\n",
        "metadata = ['station_id',\n",
        "            'time']\n",
        "\n",
        "# Set variables based on data type (typed)\n",
        "\n",
        "dataset_id = 'IWaveBNetwork_spectral'\n",
        "syear = 2008    \n",
        "master_params = ['PeakPeriod',\n",
        "                  'PeakDirection',\n",
        "                  'PeakSpread',\n",
        "                  'SignificantWaveHeight',\n",
        "                  'EnergyPeriod',\n",
        "                  'MeanWavePeriod_Tm01',\n",
        "                  'MeanWavePeriod_Tm02',\n",
        "                    'qcflag']\n",
        "\n",
        "\n",
        "\n",
        "# Generate parameter component of URL\n",
        "plist = ''\n",
        "for item in metadata + master_params:\n",
        "    plist = plist+item+'%2C'\n",
        "plist = plist[0:-3]\n",
        "\n",
        "# Create dataframe for population\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Iterate by year to reduce risk of time out on large time-series\n",
        "years = range(syear,now.year)\n",
        "for year in years:    \n",
        "    url = s+\"/\"+p+\"/\"+dataset_id+\".\"+r+\"?\"+plist+\"&time%3E=\"+str(year)+\"-01-01T00:00:00Z&time%3C\"+str(year+1)+\"-01-01T00:00:00Z\"\n",
        "    dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
        "    df = pd.concat([df,dfbyyear])\n",
        "    print(\"Downloaded %s\" % (year))\n",
        "\n",
        "# Final call for data from start of current year upto midnight of the current day\n",
        "url = s+\"/\"+p+\"/\"+dataset_id+\".\"+r+\"?\"+plist+\"&time%3E=\"+str(now.year)+\"-01-01T00:00:00Z&time%3C\"+now_string+\"T00:00:00Z\"\n",
        "dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
        "df = pd.concat([df,dfbyyear])\n",
        "print(\"Downloaded %s\" % (str(now.year)))\n",
        "\n",
        "# Make a copy of the unaltered data download\n",
        "data_full_wave_spectral = df.copy()\n",
        "print(\"Full resolution data downloaded. Available as 'data_full_wave_spectral'.\")\n",
        "df.to_csv('wave_spectral', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wave_spectral\n",
            "Downloaded 2008\n",
            "Downloaded 2009\n",
            "Downloaded 2010\n",
            "Downloaded 2011\n",
            "Downloaded 2012\n",
            "Downloaded 2013\n",
            "Downloaded 2014\n",
            "Downloaded 2015\n",
            "Downloaded 2016\n",
            "Downloaded 2017\n",
            "Downloaded 2018\n",
            "Downloaded 2019\n",
            "Downloaded 2020\n",
            "Downloaded 2021\n",
            "Full resolution data downloaded. Available as 'data_full_wave_spectral'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm0jd2y_z4gN",
        "outputId": "2071029c-74be-42a4-aba4-2677f14e9847"
      },
      "source": [
        "typed = 'wave_zero'\n",
        "print(typed)\n",
        "\n",
        "# Set ERDDAP server details\n",
        "s = 'https://erddap.marine.ie/erddap'\n",
        "p = 'tabledap'\n",
        "r = 'csv'\n",
        "\n",
        "# Set global variables for the parameters without 'buoy_id', 'latitude' and 'longitude' in the list\n",
        "now = datetime.date.today()\n",
        "now_string = now.strftime('%Y-%m-%d')\n",
        "\n",
        "metadata = ['station_id',\n",
        "            'time']\n",
        "\n",
        "# Set variables based on data type (typed)\n",
        "\n",
        "\n",
        "dataset_id = 'IWaveBNetwork_zerocrossing'\n",
        "syear = 2008    \n",
        "master_params = ['Hmax',\n",
        "                  'HmaxPeriod',\n",
        "                  'Havg',\n",
        "                  'Tavg',\n",
        "                  'qcflag']\n",
        "\n",
        "\n",
        "\n",
        "# Generate parameter component of URL\n",
        "plist = ''\n",
        "for item in metadata + master_params:\n",
        "    plist = plist+item+'%2C'\n",
        "plist = plist[0:-3]\n",
        "\n",
        "# Create dataframe for population\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Iterate by year to reduce risk of time out on large time-series\n",
        "years = range(syear,now.year)\n",
        "for year in years:    \n",
        "    url = s+\"/\"+p+\"/\"+dataset_id+\".\"+r+\"?\"+plist+\"&time%3E=\"+str(year)+\"-01-01T00:00:00Z&time%3C\"+str(year+1)+\"-01-01T00:00:00Z\"\n",
        "    dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
        "    df = pd.concat([df,dfbyyear])\n",
        "    print(\"Downloaded %s\" % (year))\n",
        "\n",
        "# Final call for data from start of current year upto midnight of the current day\n",
        "url = s+\"/\"+p+\"/\"+dataset_id+\".\"+r+\"?\"+plist+\"&time%3E=\"+str(now.year)+\"-01-01T00:00:00Z&time%3C\"+now_string+\"T00:00:00Z\"\n",
        "dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
        "df = pd.concat([df,dfbyyear])\n",
        "print(\"Downloaded %s\" % (str(now.year)))\n",
        "\n",
        "# Make a copy of the unaltered data download\n",
        "data_full_wave_zero = df.copy()\n",
        "print(\"Full resolution data downloaded. Available as 'data_full_wave_zero'.\")\n",
        "df.to_csv('wave_zero', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wave_zero\n",
            "Downloaded 2008\n",
            "Downloaded 2009\n",
            "Downloaded 2010\n",
            "Downloaded 2011\n",
            "Downloaded 2012\n",
            "Downloaded 2013\n",
            "Downloaded 2014\n",
            "Downloaded 2015\n",
            "Downloaded 2016\n",
            "Downloaded 2017\n",
            "Downloaded 2018\n",
            "Downloaded 2019\n",
            "Downloaded 2020\n",
            "Downloaded 2021\n",
            "Full resolution data downloaded. Available as 'data_full_wave_zero'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dtksnkA1EFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "747ec5ef-1df7-4604-e65f-216ee435970b"
      },
      "source": [
        "typed = 'weather'\n",
        "print(typed)\n",
        "\n",
        "# Set ERDDAP server details\n",
        "s = 'https://erddap.marine.ie/erddap'\n",
        "p = 'tabledap'\n",
        "r = 'csv'\n",
        "\n",
        "# Set global variables for the parameters without 'buoy_id', 'latitude' and 'longitude' in the list\n",
        "now = datetime.date.today()\n",
        "now_string = now.strftime('%Y-%m-%d')\n",
        "\n",
        "metadata = ['station_id',\n",
        "            'time']\n",
        "\n",
        "# Set variables based on data type (typed)\n",
        "\n",
        "\n",
        "dataset_id = 'IWaveBNetwork_zerocrossing'\n",
        "syear = 2008    \n",
        "master_params = ['Hmax',\n",
        "                  'HmaxPeriod',\n",
        "                  'Havg',\n",
        "                  'Tavg',\n",
        "                  'qcflag']\n",
        "\n",
        "\n",
        "\n",
        "# Generate parameter component of URL\n",
        "plist = ''\n",
        "for item in metadata + master_params:\n",
        "    plist = plist+item+'%2C'\n",
        "plist = plist[0:-3]\n",
        "\n",
        "# Create dataframe for population\n",
        "df = pd.DataFrame()\n",
        "\n",
        "# Iterate by year to reduce risk of time out on large time-series\n",
        "years = range(syear,now.year)\n",
        "for year in years:    \n",
        "    url = s+\"/\"+p+\"/\"+dataset_id+\".\"+r+\"?\"+plist+\"&time%3E=\"+str(year)+\"-01-01T00:00:00Z&time%3C\"+str(year+1)+\"-01-01T00:00:00Z\"\n",
        "    dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
        "    df = pd.concat([df,dfbyyear])\n",
        "    print(\"Downloaded %s\" % (year))\n",
        "\n",
        "# Final call for data from start of current year upto midnight of the current day\n",
        "url = s+\"/\"+p+\"/\"+dataset_id+\".\"+r+\"?\"+plist+\"&time%3E=\"+str(now.year)+\"-01-01T00:00:00Z&time%3C\"+now_string+\"T00:00:00Z\"\n",
        "dfbyyear = pd.read_csv(url,index_col=1,header=[0],skiprows=[1],parse_dates=True,infer_datetime_format=True)\n",
        "df = pd.concat([df,dfbyyear])\n",
        "print(\"Downloaded %s\" % (str(now.year)))\n",
        "\n",
        "# Make a copy of the unaltered data download\n",
        "data_full_wave_zero = df.copy()\n",
        "print(\"Full resolution data downloaded. Available as 'data_full_weather'.\")\n",
        "df.to_csv('weather', encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weather\n",
            "Downloaded 2008\n",
            "Downloaded 2009\n",
            "Downloaded 2010\n",
            "Downloaded 2011\n",
            "Downloaded 2012\n",
            "Downloaded 2013\n",
            "Downloaded 2014\n",
            "Downloaded 2015\n",
            "Downloaded 2016\n",
            "Downloaded 2017\n",
            "Downloaded 2018\n",
            "Downloaded 2019\n",
            "Downloaded 2020\n",
            "Downloaded 2021\n",
            "Full resolution data downloaded. Available as 'data_full_weather'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tbIM-8puCQC",
        "outputId": "16387635-446e-4235-b353-2216d5fd63a8"
      },
      "source": [
        "# Utilise quality control flags to clean data set\n",
        "# Code to be added...\n",
        "\n",
        "\n",
        "\n",
        "# Take a working copy of the downloaded data\n",
        "data = df.copy()\n",
        "\n",
        "# Add columns for date variable\n",
        "data['Date'] = data.index.date\n",
        "\n",
        "# Get a count of data points grouped by station and date\n",
        "data_summ = data.groupby(['station_id','Date']).count().reset_index(level=['station_id','Date'])\n",
        "\n",
        "# Create master availability dataframe to hold count converted to percentage of expected data points per day\n",
        "data_avail = pd.DataFrame()  \n",
        "\n",
        "# Loop through each station due to different data resolutions and calculate percentages\n",
        "for stn in data_summ.station_id.unique().tolist():\n",
        "    data_stn = data_summ[data_summ['station_id']==stn].copy()\n",
        "\n",
        "    # Set the expected number of data points per day for a buoy type or station\n",
        "    if typed == 'weather' or stn == 'Westwave MK4':\n",
        "        res=24\n",
        "    else:\n",
        "        res=48\n",
        "\n",
        "    # Convert counts to percentage\n",
        "    data_stn.loc[:,master_params] = data_stn.loc[:,master_params]/res*100\n",
        "    \n",
        "\n",
        "    # Expand date range to cover full months.\n",
        "    # Enables accurate calculation of monthly perentage return from the daily data when plotting\n",
        "    data_fulldates = pd.DataFrame(index = pd.date_range(data_stn.Date.min() - datetime.timedelta(days=data_stn.Date.min().day-1), \n",
        "                                                      data_stn.Date.max()))\n",
        "\n",
        "    # Add date factors to faciliate plotting\n",
        "    data_fulldates['Date'] = data_fulldates.index.date\n",
        "    data_fulldates['Year'] = data_fulldates.index.year\n",
        "    data_fulldates['Month'] = data_fulldates.index.month\n",
        "    data_fulldates['DOY'] = data_fulldates.index.dayofyear\n",
        "    \n",
        "    # Merge individual station dataframe into master availability dataframe and fill blanks dates with zero\n",
        "    data_fulldates = data_fulldates.merge(data_stn, how='outer', left_on='Date', right_on='Date').fillna(0)\n",
        "    # Set station\n",
        "    data_fulldates.loc[:,'station_id'] = stn\n",
        "    # Add data for the station to the master availability data frame\n",
        "    data_avail = pd.concat([data_avail,data_fulldates])\n",
        "\n",
        "# Set indices and tidy up dataframe\n",
        "data_avail = data_avail.set_index(['station_id', 'Date','Year','Month','DOY'])\n",
        "\n",
        "if typed != 'weather':\n",
        "    qc = 'qcflag'\n",
        "else:\n",
        "    qc = 'QC_Flag'\n",
        "\n",
        "data_avail = data_avail.drop(['qcflag'], axis=1)\n",
        "data_avail.columns = pd.MultiIndex.from_product([data_avail.columns, ['avail']])\n",
        "\n",
        "print(\"Daily availability generated. Available as 'data_avail'.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Daily availability generated. Available as 'data_avail'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "AF3sqLOKuHZa",
        "outputId": "b94aabe4-32ab-47e1-842e-ce7d94cc1588"
      },
      "source": [
        "data_avail.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Hmax</th>\n",
              "      <th>HmaxPeriod</th>\n",
              "      <th>Havg</th>\n",
              "      <th>Tavg</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>avail</th>\n",
              "      <th>avail</th>\n",
              "      <th>avail</th>\n",
              "      <th>avail</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>station_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>DOY</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">AMETS Berth A Wave Buoy</th>\n",
              "      <th>2012-05-01</th>\n",
              "      <th>2012</th>\n",
              "      <th>5</th>\n",
              "      <th>122</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-05-02</th>\n",
              "      <th>2012</th>\n",
              "      <th>5</th>\n",
              "      <th>123</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-05-03</th>\n",
              "      <th>2012</th>\n",
              "      <th>5</th>\n",
              "      <th>124</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-05-04</th>\n",
              "      <th>2012</th>\n",
              "      <th>5</th>\n",
              "      <th>125</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-05-05</th>\n",
              "      <th>2012</th>\n",
              "      <th>5</th>\n",
              "      <th>126</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Hmax HmaxPeriod  Havg  Tavg\n",
              "                                                  avail      avail avail avail\n",
              "station_id              Date       Year Month DOY                             \n",
              "AMETS Berth A Wave Buoy 2012-05-01 2012 5     122   0.0        0.0   0.0   0.0\n",
              "                        2012-05-02 2012 5     123   0.0        0.0   0.0   0.0\n",
              "                        2012-05-03 2012 5     124   0.0        0.0   0.0   0.0\n",
              "                        2012-05-04 2012 5     125   0.0        0.0   0.0   0.0\n",
              "                        2012-05-05 2012 5     126   0.0        0.0   0.0   0.0"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}